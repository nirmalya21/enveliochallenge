{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4b7b45-9644-43ac-b906-2231a869f309",
   "metadata": {},
   "source": [
    "# Model Inference Notebook\n",
    "1. **Model Loading & Preprocessing:**  \n",
    "   - Load the saved model.\n",
    "   - Replicate any necessary preprocessing steps.\n",
    "2. **Inference and Forecasting:**  \n",
    "   - Demonstrate how to perform inference/forecasting on new data.\n",
    "   - Clearly explain each step in the inference process.\n",
    "3. **Practical Considerations:**  \n",
    "   - Optionally, discuss potential improvements, limitations, and next steps\n",
    "     (e.g., include a \"Next Steps / Future Work\" section).\n",
    "   - **Important:** Include all relevant outputs so that your evaluation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b00c6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model loading and preprocessing steps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the saved XGBoost model\n",
    "model = xgb.Booster()\n",
    "model.load_model(\"models/xgboost_model.json")\n",
    "\n",
    "# Load new data (replace 'new_data.csv' with actual file)\n",
    "df = pd.read_csv(\"/home/nirmalya/Documents/new_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c12b8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replicate the process of data pre-processing\n",
    "scaler = joblib.load(\"models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53db1c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  predicted_current_A\n",
      "0  2024-01-01 01:00:00             5.116937\n",
      "1  2024-01-01 02:00:00             5.116937\n",
      "2  2024-01-01 03:00:00             5.116937\n",
      "3  2024-01-01 04:00:00             5.116937\n",
      "4  2024-01-01 05:00:00             5.116937\n",
      "5  2024-01-01 06:00:00             5.116937\n",
      "6  2024-01-01 07:00:00             5.116937\n",
      "7  2024-01-01 08:00:00             5.116937\n",
      "8  2024-01-01 09:00:00             6.615566\n",
      "9  2024-01-01 10:00:00            10.173897\n",
      "10 2024-01-01 11:00:00             9.227261\n",
      "11 2024-01-01 12:00:00            12.410575\n",
      "12 2024-01-01 13:00:00            10.581490\n",
      "13 2024-01-01 14:00:00             6.449881\n",
      "14 2024-01-01 15:00:00             9.889564\n",
      "15 2024-01-01 16:00:00            11.728443\n",
      "16 2024-01-01 17:00:00            10.878566\n",
      "17 2024-01-01 18:00:00            10.312428\n",
      "18 2024-01-01 19:00:00            10.417892\n",
      "19 2024-01-01 20:00:00            14.049781\n",
      "20 2024-01-01 21:00:00            11.819494\n",
      "21 2024-01-01 22:00:00             9.799755\n",
      "22 2024-01-01 23:00:00            10.488949\n",
      "23 2024-01-02 00:00:00             5.922047\n"
     ]
    }
   ],
   "source": [
    "#replicate the process of data pre-processing\n",
    "# Ensure timestamp exists and parse correctly\n",
    "if 'timestamp' in df_new.columns:\n",
    "    df_new['timestamp'] = pd.to_datetime(df_new['timestamp'])\n",
    "    df_new = df_new.sort_values(by='timestamp')\n",
    "else:\n",
    "    raise ValueError(\"Column 'timestamp' is missing in the dataset.\")\n",
    "\n",
    "# Load the fitted scaler\n",
    "scaler = joblib.load(\"/home/nirmalya/Documents/models/scaler.pkl\")\n",
    "\n",
    "#inference and forecasting\n",
    "# Define the feature engineering function\n",
    "def create_features(df):\n",
    "    # Create lag features for all necessary variables\n",
    "    for lag in range(1, 25):  # Up to 24 hours of lag\n",
    "        df[f'lag_current_{lag}'] = df['current_A'].shift(lag)\n",
    "        df[f'lag_temperature_{lag}'] = df['temperature_C'].shift(lag)\n",
    "        df[f'lag_wind_speed_{lag}'] = df['wind_speed_mps'].shift(lag)\n",
    "        df[f'lag_solar_radiation_{lag}'] = df['solar_radiation_Wpm2'].shift(lag)\n",
    "\n",
    "    # Create rolling mean features\n",
    "    for window in [3, 6, 12, 24]:\n",
    "        df[f'rolling_mean_{window}'] = df['current_A'].rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "    # Handle NaN values\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to the new data\n",
    "df_new = create_features(df_new)\n",
    "\n",
    "# Define feature columns used for training\n",
    "feature_columns = [\n",
    "    'temperature_C',\n",
    "    'wind_speed_mps',\n",
    "    'solar_radiation_Wpm2',\n",
    "] + [f'lag_current_{lag}' for lag in range(1, 25)] + \\\n",
    "  [f'lag_temperature_{lag}' for lag in range(1, 25)] + \\\n",
    "  [f'lag_wind_speed_{lag}' for lag in range(1, 25)] + \\\n",
    "  [f'lag_solar_radiation_{lag}' for lag in range(1, 25)] + \\\n",
    "  [f'rolling_mean_{window}' for window in [3, 6, 12, 24]]\n",
    "\n",
    "# Ensure all necessary features are in the new DataFrame\n",
    "df_new_scaled = df_new[feature_columns]\n",
    "\n",
    "# Scale the new features using the fitted scaler\n",
    "X_new_scaled = scaler.transform(df_new_scaled)\n",
    "\n",
    "# Step 5: Make Predictions\n",
    "predictions = model.predict(xgb.DMatrix(X_new_scaled))\n",
    "\n",
    "# Get the last timestamp from the new data\n",
    "last_timestamp = df_new['timestamp'].iloc[-1]\n",
    "\n",
    "# Define the number of future hours you want to forecast (e.g., 24 hours)\n",
    "future_hours = 24\n",
    "\n",
    "# Generate new timestamps for the forecast period (hourly frequency)\n",
    "new_timestamps = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1),\n",
    "                               periods=future_hours, freq='H')\n",
    "\n",
    "# Limit the predictions to the forecast period (if your model predicts more rows)\n",
    "predictions_future = predictions[:future_hours]\n",
    "\n",
    "# Create a DataFrame for the forecasts\n",
    "predictions_df = pd.DataFrame({\n",
    "    'timestamp': new_timestamps,\n",
    "    'predicted_current_A': predictions_future\n",
    "})\n",
    "\n",
    "# Reset the index if needed\n",
    "predictions_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c491d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Practical Considerations\n",
    "\n",
    "#3.1 Potential Improvements\n",
    "#1.Model Exploration: Experiment with alternative models (e.g., LSTM, ARIMA) to potentially improve forecasting accuracy.\n",
    "#Feature Engineering: Enhance feature engineering by including external data (e.g., weather forecasts) or by exploring different lag windows.\n",
    "#Hyperparameter Tuning: Use cross-validation and grid/random search to optimize model hyperparameters.\n",
    "\n",
    "#3.2 Limitations\n",
    "#Data Quality: Forecasting accuracy heavily depends on the quality and quantity of historical data.\n",
    "#Model Generalization: The current model might not capture sudden changes or external influences not present in historical data.\n",
    "\n",
    "#3.3 Next Steps / Future Work\n",
    "#Model Evaluation: Validate model predictions on a hold-out dataset and evaluate using metrics such as MAE or RMSE.\n",
    "#Interpretability: Analyze feature importance to gain insights into the model's decision-making process.\n",
    "#Deployment: Integrate the model into a real-time forecasting system and set up monitoring for model drift.\n",
    "#Automation: Automate data ingestion, model retraining, and forecast generation in a production pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
